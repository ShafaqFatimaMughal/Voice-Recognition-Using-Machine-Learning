# -*- coding: utf-8 -*-
"""Voice_Recognition_ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12RZmCdpdIcRbsfSQWeboequJcEh-iDfm

# Loading Libraries
"""

import librosa
# import os
# from google.colab import drive
# from google.colab import files
import math
# from tqdm import tqdm
import numpy as np
# import pandas as pd
import json
import matplotlib.pyplot as plt
# from sklearn.model_selection import train_test_split
from statistics import mode
# import seaborn as sns
# from sklearn.metrics import confusion_matrix
# import pickle

# drive.mount('/content/drive') # mounting drive so that we can access the dataset that has been uploaded

# """#Curating Dataset

# ## Initializing Paths
# """

# training_dataset_path = "/content/drive/MyDrive/AI_voice_data/TrainingData" # path of data saved in drive
# training_mfcc_json_path = "/content/drive/MyDrive/AI_voice_data/train_mfcc_data.json" # path of json when json created first time
# training_stft_json_path = "/content/drive/MyDrive/AI_voice_data/train_stft_data.json" # path of json when json created first time

"""##Setting Hyper-Parametes"""

# Hyper-parameters for Audio Images
SAMPLE_RATE = 22050
TRACK_SAMPLE = 10
NUM_CLASSES = 10
num_mfcc = 32
hop_length = 512

# Hyper-paremeters for MLP
EPOCHS = 30
TRAIN_TEST_SPLIT = 0.2
LEARNING_RATE = 0.0005
BATCH_SIZE = 10
SHUFFLE_DATA = True

# # Mode for stft or mfcc
# Image = "mfcc"

# # If you want to save
# save = True

# # If you want to Create new JSON or Load JSON Data from drive
# create = False

# """## Creating MFCC Dataset"""

# def save_audio_features(dataset_path, json_path, image=Image):
#     data = {
#         "mapping": [],
#         "labels": [],
#         "image": []
#     }

#     for root, _, files in os.walk(dataset_path):
#       for _, name in tqdm(enumerate(files)):
#             file_path = os.path.join(root, name)
#             person = name.split(".")[0].split("_")[0] # getting the name of the person from the dataset filename

#             if person in data["mapping"]: # add person's name only if it is not already added
#               pass
#             else:
#               data["mapping"].append(person) 

#             signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)
#             duration = librosa.get_duration(y=signal, sr=sample_rate) # duration in seconds
            
#             d = 0
            
#             print(data["mapping"][-1])

#             for i in range(0, math.floor(duration), TRACK_SAMPLE): # generating mfccs for 10s segments of audio

#                 if (i+10) > duration:
#                   continue
                
#                 start = i * SAMPLE_RATE
#                 finish = (i + TRACK_SAMPLE) * SAMPLE_RATE

#                 # Shape (431, 32)
#                 if image == "mfcc":
#                     img = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft = 2048, hop_length=hop_length) 
#                     img = img.T

#                 else:
#                     img = librosa.stft(signal[start:finish], n_fft = 512, hop_length = hop_length)
#                     img = np.abs(img.T)

#                 data["image"].append(img.tolist()) # converting to lst as numpy arr not stored by json file
#                 data["labels"].append(data["mapping"].index(person)) # stores the genre label index

#                 # print("{}, segment:{}".format(file_path, d+1))
#                 d += 1

#     # creating a json file to save all mfccs and relevant details of each song segment
#     with open(json_path, "w") as fp:
#         json.dump(data, fp, indent=4)

"""# Creating our MLP model

## Layer Class
"""

class Layer:
    """
    A building block. Each layer is capable of performing two things:
    i) Process input to get output:           output = layer.forward(input)
    ii) Propagate gradients through itself:    grad_input = layer.backward(input, grad_output)
    
    Some layers also have learnable parameters which they update during layer.backward.
    """

    def __init__(self):
        """
        Here we can initialize layer parameters (if any) and auxiliary stuff
        """
        pass # A dummy layer does nothing
    
    def forward(self, input):
        """
        Takes input data of shape [batch, input_units], returns output data [batch, output_units]
        """
        return input # A dummy layer just returns whatever it gets as input

    def backward(self, input, grad_output):
        """
        Performs a backpropagation step through the layer, with respect to the given input.
        
        To compute loss gradients w.r.t input, we need to apply chain rule (backprop):
        
        d loss / d x  = (d loss / d layer) * (d layer / d x)
        
        Luckily, we already receive d loss / d layer as input, so you only need to multiply it by d layer / d x.
        
        If our layer has parameters (e.g. dense layer), we also need to update them here using d loss / d layer
        """
        # The gradient of a dummy layer is precisely grad_output, but we'll write it more explicitly
        num_units = input.shape[1]
        
        d_layer_d_input = np.eye(num_units)
        
        return np.dot(grad_output, d_layer_d_input) # chain rule

"""## Relu Activation"""

class ReLU(Layer):
    def __init__(self):
        """ReLU layer simply applies elementwise rectified linear unit to all inputs"""
        pass
    
    def forward(self, input):
        """Apply elementwise ReLU to [batch, input_units] matrix"""
        relu_forward = np.maximum(0,input)
        return relu_forward
    
    def backward(self, input, grad_output):
        """Compute gradient of loss w.r.t. ReLU input"""
        relu_grad = input > 0
        return grad_output*relu_grad

"""## Sigmoid Activation"""

class Sigmoid(Layer):
    def __init__(self):
        """Sigmoid layer simply applies sigmoid activation function to all inputs"""
        pass
    
    def forward(self, input):
        """Apply elementwise sigmoid to [batch, input_units] matrix"""
        sigmoid_forward = 1/(1+np.exp(-input))
        return sigmoid_forward
    
    def backward(self, input, grad_output):
        """Compute gradient of loss w.r.t. Sigmoid input"""
        sigmoid_forward = 1/(1+np.exp(-input))
        sigmoid_grad = sigmoid_forward*(1-sigmoid_forward)
        return grad_output*sigmoid_grad

"""## Dense Layer"""

class Dense(Layer):
    def __init__(self, input_units, output_units, learning_rate=0.01):
        """
        A dense layer is a layer which performs a learned affine transformation:
        f(x) = <X,W> + b
        """
        self.learning_rate = learning_rate
        self.weights = np.random.normal(loc=0.0, scale = np.sqrt(2/(input_units+output_units)), size = (input_units,output_units))
        self.biases = np.zeros(output_units)
        
    def forward(self,input):
        """
        Perform an affine transformation:
        f(x) = <X,W> + b
        
        input shape: [batch, input_units]
        output shape: [batch, output units]
        """
        return np.dot(input,self.weights) + self.biases
    
    def backward(self,input,grad_output):
        # compute d f / d x = d f / d dense * d dense / d x
        # where d dense/ d x = weights transposed
        grad_input = np.dot(grad_output, self.weights.T)
        
        # compute gradient w.r.t. weights and biases
        grad_weights = np.dot(input.T, grad_output)/input.shape[0]


        grad_biases = grad_output.sum(axis=0)/input.shape[0]
        
        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape
        
        # perform a stochastic gradient descent step. 
        self.weights = self.weights - self.learning_rate * grad_weights
        self.biases = self.biases - self.learning_rate * grad_biases
        
        return grad_input

"""## Loss Functions"""

def softmax(z):
  exp = np.exp(z-np.max(z,axis=1, keepdims=True))
  probs = exp/np.sum(exp,axis=1, keepdims=True)
  return probs

def one_hot(y,c):
   y_hot = np.zeros((len(y), c))
   y_hot[np.arange(len(y)), y] = 1
   return y_hot

def cross_entropy_loss(logits,y):
   y_hat = softmax(logits)
   y_hot = one_hot(y, NUM_CLASSES)
   loss = -np.sum(np.log(y_hat)*y_hot)/y.shape[0]
   return loss

def grad_cross_entropy_loss(logits,y):
    y_hat = softmax(logits)
    y_hot = one_hot(y, NUM_CLASSES)
    return (y_hat - y_hot)

"""## Main MLP Class"""

class MLP:
  def __init__(self,n) -> None:
      self.network = n
  
  def forward(self, X):
    """
    Compute activations of all network layers by applying them sequentially.
    Return a list of activations for each layer. 
    """
    activations = []
    input = X

    # Looping through each layer
    for l in self.network:
        activations.append(l.forward(input))
        # Updating input to last layer output
        input = activations[-1]
    
    assert len(activations) == len(self.network)
    return activations

  def predict(self,X):
      """
      Compute network predictions. Returning indices of largest Logit probability
      """
      logits = self.forward(X)[-1]
      return np.argmax(softmax(logits),axis=1)
  
  def train(self,X,y):
      """
      Train our network on a given batch of X and y.
      We first need to run forward to get all layer activations.
      Then we can run layer.backward going from last to first layer.
      After we have called backward for all layers, all Dense layers have already made one gradient step.
      """
      
      # Get the layer activations
      layer_activations = self.forward(X)
      layer_inputs = [X]+layer_activations  #layer_input[i] is an input for network[i]
      logits = layer_activations[-1]
      
      # Compute the loss and the initial gradient
      loss = cross_entropy_loss(logits,y)
      loss_grad = grad_cross_entropy_loss(logits,y)
      
      # Propagate gradients through the network
      # Reverse propogation as this is backprop
      for layer_index in range(len(self.network))[::-1]:
          layer = self.network[layer_index]       
          loss_grad = layer.backward(layer_inputs[layer_index],loss_grad) #grad w.r.t. input, also weight updates
          
      return np.mean(loss)

# """# Loading Dataset"""

# def load_data(data_path): # open and read json from given path
#     with open(data_path, "r") as fp:
#         data = json.load(fp)

#     # save mfcc in X and relevant data in y and z
#     X = np.array(data["image"])
#     y = np.array(data["labels"]) # indexes of the names that correspond to mapping
#     z = np.array(data["mapping"]) # names

#     arr = np.array(range(len(X)))
#     perm = np.random.permutation(arr)

#     X = X[perm]
#     y = y[perm]
#     return X, y, z

# def prepare_datasets(dataset_path, test_size):
#     X, y, z = load_data(dataset_path) # load data

#     # plotting bar chart to visualize dataset
#     unique, counts = np.unique(y, return_counts=True) # unique indexes and the frequecnt of each in counts
#     dictionary = dict(zip(unique, counts))
#     new_dic = {}

#     for i in dictionary:
#         new_dic[z[i]] = dictionary[i] # Key value pair with name and frequency
    
#     plt.bar(list(new_dic.keys()), height=list(new_dic.values()))
#     plt.xticks(rotation=45) # tilt labels to avoid overlap
#     plt.show()

#     # create train test split
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)

#     # add an axis to input sets
#     X_train = X_train[..., np.newaxis]
#     X_test = X_test[..., np.newaxis]

#     return X_train, X_test, y_train,  y_test, z

# """## Creating or Loading JSON

# Create JSON from Dataset
# """

# if create == True:
#     # Create and Load Dataset from notebook
#     if Image == "mfcc":
#         # mfcc
#         save_audio_features(training_dataset_path, training_mfcc_json_path, Image) # Creating Training Data from dataset
#         X_train, X_test, y_train,  y_test, z = prepare_datasets(training_mfcc_json_path, TRAIN_TEST_SPLIT)

#     else:
#         # stft
#         save_audio_features(training_dataset_path, training_stft_json_path, Image) # Creating Training Data from dataset
#         X_train, X_test, y_train,  y_test, z = prepare_datasets(training_stft_json_path, TRAIN_TEST_SPLIT)

# else:
#     if Image == "mfcc":
#         # Loading MFCC JSON from Drive
#         drive_mfcc_json_path = "/content/drive/MyDrive/AI_voice_data/train_mfcc_data.json"
#         X_train, X_test, y_train,  y_test, z = prepare_datasets(drive_mfcc_json_path, TRAIN_TEST_SPLIT)

#     else:
#         # Loading STFT JSON from Drive
#         drive_stft_json_path = "/content/drive/MyDrive/AI_voice_data/train_stft_data.json"
#         X_train, X_test, y_train,  y_test, z = prepare_datasets(drive_stft_json_path, TRAIN_TEST_SPLIT)

# """Flattening the Data For MLP"""

# X_train_flatten = X_train.reshape((X_train.shape[0], -1))
# X_test_flatten = X_test.reshape((X_test.shape[0], -1))

# """# Initializing Model"""

# network = []
# train_log = [0]
# val_log = []
# loss_log = []

# # X_train_flatten.shape[1] is input layer
# network.append(Dense(X_train_flatten.shape[1], 1024, learning_rate = LEARNING_RATE)) # Hidden layer with 1024 nuerons
# network.append(ReLU()) # aaply RELU to hidden layer output
# network.append(Dense(1024, NUM_CLASSES, learning_rate = LEARNING_RATE)) # Output layer

# model = MLP(n=network)

# """# Training Model"""

# # Minibatch Stochastic Gradient Descent
# def iterate_minibatches(inputs, targets, batchsize, shuffle=False):
#     assert len(inputs) == len(targets)
#     if shuffle:
#         indices = np.random.permutation(len(inputs))
#     for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):
#         if shuffle:
#             excerpt = indices[start_idx:start_idx + batchsize]
#         else:
#             excerpt = slice(start_idx, start_idx + batchsize)
#         yield inputs[excerpt], targets[excerpt]

# # Training the model
# for epoch in tqdm(range(EPOCHS), desc = "Training"):
#     loss = 0.0
#     num_batches = 0
#     for x_batch,y_batch in iterate_minibatches(X_train_flatten, y_train, batchsize=BATCH_SIZE, shuffle=SHUFFLE_DATA):
#         loss += model.train(x_batch, y_batch)
#         num_batches += 1

#     train_log.append(np.mean(model.predict(X_train_flatten)==y_train))
#     loss_log.append(loss/num_batches)

#     print("Epoch", epoch)
#     print("Train accuracy:", train_log[-1], " Training Loss:", loss_log[-1])

# plt.plot(train_log, label='Train Accuracy')
# plt.plot(loss_log, label="Training Loss")
# plt.legend(loc='best')
# plt.grid()
# plt.show()

# # testing and printing predictions on all of the test data
# preds = []
# print("Predicting on all song segments from test data and saving them too...")

# # predicting X test values one by one and sotring
# for i in range(len(X_test_flatten)):
#   y_pred = model.predict(X_test_flatten[i].reshape((1, -1)))
#   preds.append(y_pred[0])

# # Confusion matrix
# cm = confusion_matrix(y_test, preds)

# class_label = z # mapping in json had a list of all classes
# df_cm = pd.DataFrame(cm, index = class_label, columns = class_label)
# sns.heatmap(df_cm, annot = True, fmt= "d", cbar = False)
# plt.title("Confusion Matrix")
# plt.xlabel("Predicted Label")
# plt.ylabel("Actual Label")
# plt.show()

# # Calculating accuracy of model on test set
# accuracy = np.mean(y_test==preds)
# print("\nTest Accuracy:", accuracy)

# """#Validating Data on Outside data"""

def new_voice_predict(audio_path, model, z, Image):
    name = audio_path.split("/")[-1].split("_")[0]
    signal, sample_rate = librosa.load(audio_path, sr=SAMPLE_RATE)
    duration = librosa.get_duration(y=signal, sr=sample_rate) # duration in seconds
    results = []

    d = 0
    for i in range(0, math.floor(duration), TRACK_SAMPLE): # generating mfccs for 10s segments of audio

        if (i+10) > duration:
          continue
    
        if d == 5:
          break
        start = i * SAMPLE_RATE
        finish = (i + TRACK_SAMPLE) * SAMPLE_RATE

        if Image == "mfcc":
            img = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=2048, hop_length=hop_length)
            img = img.T

        else:
            img = librosa.stft(signal[start:finish], n_fft = 512, hop_length = hop_length)
            img = np.abs(img.T)

        data = np.array(img.tolist()) # converting to lst
        data = data.reshape((1, -1)) # flattening
        
        prediction = model.predict(data)
        results.append(prediction[0])
        
        d+=1

    return z[mode(results)], name

# # Testing model on new data
# fname = "Fizza Rubab_Test.wav"

# expected, actual = new_voice_predict("/content/drive/MyDrive/AI_voice_data/TestingData/"+ fname, model, z, Image)

# print("Voice Audio Results => Expected:{}, Actual:{}. Correct Prediction:{}".format(expected, actual, bool(expected==actual)))

# # Save the model to disk
# model_loc = "/content/drive/MyDrive/AI_voice_data/"

# if save==True:
#     if Image == "mfcc":
#         # mfcc
#         filename = model_loc + 'mfcc_VoiceRecognitionModel.pkl'

#     else:
#         # stft
#         filename = model_loc + 'stft_VoiceRecognitionModel.pkl'

#     pickle.dump(model, open(filename, 'wb'))

# # Testing by loading the model
# path = "/content/drive/MyDrive/AI_voice_data/TestingData/"
# fname = "Akeel Athar_Test.wav"

# if Image == "mfcc":
#     # mfcc
#     loaded_model = pickle.load(open('/content/drive/MyDrive/AI_voice_data/mfcc_VoiceRecognitionModel.pkl', 'rb'))

# else:
#     # stft
#     loaded_model = pickle.load(open('/content/drive/MyDrive/AI_voice_data/stft_VoiceRecognitionModel.pkl', 'rb'))


# expected, actual = new_voice_predict(path + fname, model, z, Image)

# print("Voice Audio Results => Expected:{}, Actual:{}. Correct Prediction:{}".format(expected, actual, bool(expected==actual)))