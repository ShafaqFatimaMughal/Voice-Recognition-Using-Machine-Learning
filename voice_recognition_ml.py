# -*- coding: utf-8 -*-
"""Voice_Recognition_ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12RZmCdpdIcRbsfSQWeboequJcEh-iDfm

# Loading Libraries
"""

import librosa
# import os
# from google.colab import drive
# from google.colab import files
import math
# from tqdm import tqdm
import numpy as np
# import pandas as pd
# import json
# import matplotlib.pyplot as plt
# from sklearn.model_selection import train_test_split
from statistics import mode
# import seaborn as sns
# from sklearn.metrics import confusion_matrix
# import pickle

# drive.mount('/content/drive') # mounting drive so that we can access the dataset that has been uploaded

# """#Curating Dataset

# ## Initializing Paths
# """

# training_dataset_path = "/content/drive/MyDrive/AI_voice_data/TrainingData" # path of json saved in drive
# training_json_path = "/content/train_mfcc_data.json" # path of json when json created first time

# """##Setting Hyper-Parametes"""

# Hyper-parameters for Audio Images
SAMPLE_RATE = 22050
TRACK_SAMPLE = 10
NUM_CLASSES = 10
num_mfcc = 32
n_fft = 2048
hop_length = 512

# # Hyper-paremeters for MLP
# EPOCHS = 30
# TRAIN_TEST_SPLIT = 0.2
# LEARNING_RATE = 0.0001
# BATCH_SIZE = 10
# SHUFFLE_DATA = True

# """## Creating MFCC Dataset"""

# def save_mfcc(dataset_path, json_path):
#     data = {
#         "mapping": [],
#         "labels": [],
#         "mfcc": []
#     }

#     for root, _, files in os.walk(dataset_path):
#       for _, name in tqdm(enumerate(files)):
#             file_path = os.path.join(root, name)
#             person = name.split(".")[0].split("_")[0] # getting the name of the person from the dataset filename

#             if person in data["mapping"]: # add person's name only if it is not already added
#               pass
#             else:
#               data["mapping"].append(person) 

#             signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)
#             duration = librosa.get_duration(y=signal, sr=sample_rate) # duration in seconds
            
#             d = 0
            
#             print(data["mapping"][-1])

#             for i in range(0, math.floor(duration), TRACK_SAMPLE): # generating mfccs for 10s segments of audio

#                 if (i+10) > duration:
#                   continue
                
#                 start = i * SAMPLE_RATE
#                 finish = (i + TRACK_SAMPLE) * SAMPLE_RATE

#                 mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length) 
#                 mfcc = mfcc.T
#                 data["mfcc"].append(mfcc.tolist()) # converting to lst as numpy arr not stored by json file
#                 data["labels"].append(data["mapping"].index(person)) # stores the genre label index

#                 # print("{}, segment:{}".format(file_path, d+1))
#                 d += 1

#     # creating a json file to save all mfccs and relevant details of each song segment
#     with open(json_path, "w") as fp:
#         json.dump(data, fp, indent=4)

"""# Creating our MLP model

## Layer Class
"""

class Layer:
    """
    A building block. Each layer is capable of performing two things:
    i) Process input to get output:           output = layer.forward(input)
    ii) Propagate gradients through itself:    grad_input = layer.backward(input, grad_output)
    
    Some layers also have learnable parameters which they update during layer.backward.
    """

    def __init__(self):
        """
        Here we can initialize layer parameters (if any) and auxiliary stuff
        """
        pass # A dummy layer does nothing
    
    def forward(self, input):
        """
        Takes input data of shape [batch, input_units], returns output data [batch, output_units]
        """
        return input # A dummy layer just returns whatever it gets as input

    def backward(self, input, grad_output):
        """
        Performs a backpropagation step through the layer, with respect to the given input.
        
        To compute loss gradients w.r.t input, we need to apply chain rule (backprop):
        
        d loss / d x  = (d loss / d layer) * (d layer / d x)
        
        Luckily, we already receive d loss / d layer as input, so you only need to multiply it by d layer / d x.
        
        If our layer has parameters (e.g. dense layer), we also need to update them here using d loss / d layer
        """
        # The gradient of a dummy layer is precisely grad_output, but we'll write it more explicitly
        num_units = input.shape[1]
        
        d_layer_d_input = np.eye(num_units)
        
        return np.dot(grad_output, d_layer_d_input) # chain rule

"""## Relu Activation"""

class ReLU(Layer):
    def __init__(self):
        """ReLU layer simply applies elementwise rectified linear unit to all inputs"""
        pass
    
    def forward(self, input):
        """Apply elementwise ReLU to [batch, input_units] matrix"""
        relu_forward = np.maximum(0,input)
        return relu_forward
    
    def backward(self, input, grad_output):
        """Compute gradient of loss w.r.t. ReLU input"""
        relu_grad = input > 0
        return grad_output*relu_grad

"""## Sigmoid Activation"""

class Sigmoid(Layer):
    def __init__(self):
        """Sigmoid layer simply applies sigmoid activation function to all inputs"""
        pass
    
    def forward(self, input):
        """Apply elementwise sigmoid to [batch, input_units] matrix"""
        sigmoid_forward = 1/(1+np.exp(-input))
        return sigmoid_forward
    
    def backward(self, input, grad_output):
        """Compute gradient of loss w.r.t. Sigmoid input"""
        sigmoid_forward = 1/(1+np.exp(-input))
        sigmoid_grad = sigmoid_forward*(1-sigmoid_forward)
        return grad_output*sigmoid_grad

"""## Dense Layer"""

class Dense(Layer):
    def __init__(self, input_units, output_units, learning_rate=0.01):
        """
        A dense layer is a layer which performs a learned affine transformation:
        f(x) = <X,W> + b
        """
        self.learning_rate = learning_rate
        self.weights = np.random.normal(loc=0.0, scale = np.sqrt(2/(input_units+output_units)), size = (input_units,output_units))
        self.biases = np.zeros(output_units)
        
    def forward(self,input):
        """
        Perform an affine transformation:
        f(x) = <X,W> + b
        
        input shape: [batch, input_units]
        output shape: [batch, output units]
        """
        return np.dot(input,self.weights) + self.biases
    
    def backward(self,input,grad_output):
        # compute d f / d x = d f / d dense * d dense / d x
        # where d dense/ d x = weights transposed
        grad_input = np.dot(grad_output, self.weights.T)
        
        # compute gradient w.r.t. weights and biases
        grad_weights = np.dot(input.T, grad_output)/input.shape[0]


        grad_biases = grad_output.sum(axis=0)/input.shape[0]
        
        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape
        
        # perform a stochastic gradient descent step. 
        self.weights = self.weights - self.learning_rate * grad_weights
        self.biases = self.biases - self.learning_rate * grad_biases
        
        return grad_input

"""## Loss Functions"""

def softmax(z):
  exp = np.exp(z-np.max(z,axis=1, keepdims=True))
  probs = exp/np.sum(exp,axis=1, keepdims=True)
  return probs

# def one_hot(y,c):
#    y_hot = np.zeros((len(y), c))
#    y_hot[np.arange(len(y)), y] = 1
#    return y_hot

# def cross_entropy_loss(logits,y):
#    y_hat = softmax(logits)
#    y_hot = one_hot(y, NUM_CLASSES)
#    loss = -np.sum(np.log(y_hat)*y_hot)/y.shape[0]
#    return loss

# def grad_cross_entropy_loss(logits,y):
#     y_hat = softmax(logits)
#     y_hot = one_hot(y, NUM_CLASSES)
#     return (y_hat - y_hot)

"""## Main MLP Class"""

class MLP:
  def __init__(self,n) -> None:
      self.network = n
  def forward(self, X):
    """
    Compute activations of all network layers by applying them sequentially.
    Return a list of activations for each layer. 
    """
    activations = []
    input = X

    # Looping through each layer
    for l in self.network:
        activations.append(l.forward(input))
        # Updating input to last layer output
        input = activations[-1]
    
    assert len(activations) == len(self.network)
    return activations
  def predict(self,X):
      """
      Compute network predictions. Returning indices of largest Logit probability
      """
      logits = self.forward(X)[-1]
      return np.argmax(softmax(logits),axis=1)
  
#   def train(self,X,y):
#       """
#       Train our network on a given batch of X and y.
#       We first need to run forward to get all layer activations.
#       Then we can run layer.backward going from last to first layer.
#       After we have called backward for all layers, all Dense layers have already made one gradient step.
#       """
      
#       # Get the layer activations
#       layer_activations = self.forward(X)
#       layer_inputs = [X]+layer_activations  #layer_input[i] is an input for network[i]
#       logits = layer_activations[-1]
      
#       # Compute the loss and the initial gradient
#       loss = cross_entropy_loss(logits,y)
#       loss_grad = grad_cross_entropy_loss(logits,y)
      
#       # Propagate gradients through the network
#       # Reverse propogation as this is backprop
#       for layer_index in range(len(self.network))[::-1]:
#           layer = self.network[layer_index]       
#           loss_grad = layer.backward(layer_inputs[layer_index],loss_grad) #grad w.r.t. input, also weight updates
          
#       return np.mean(loss)

"""# Loading Dataset"""

# def load_data(data_path): # open and read json from given path
#     with open(data_path, "r") as fp:
#         data = json.load(fp)

#     # save mfcc in X and relevant data in y and z
#     X = np.array(data["mfcc"])
#     y = np.array(data["labels"]) # indexes of the names that correspond to mapping
#     z = np.array(data["mapping"]) # names
#     return X, y, z

# def prepare_datasets(dataset_path, test_size):
#     X, y, z = load_data(dataset_path) # load data

#     # create train test split
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)

#     # add an axis to input sets
#     X_train = X_train[..., np.newaxis]
#     X_test = X_test[..., np.newaxis]

#     return X_train, X_test, y_train,  y_test, z

# """## Creating or Loading JSON"""

# # Create and Load Dataset from notebook
# # save_mfcc(training_dataset_path, training_json_path) # Creating Training Data from dataset
# # X_train, X_test, y_train,  y_test, z = prepare_datasets(training_json_path, TRAIN_TEST_SPLIT)

# # Loading JSON from Drive
# drive_json_path = "/content/drive/MyDrive/AI_voice_data/train_mfcc_data.json"
# X_train, X_test, y_train,  y_test, z = prepare_datasets(drive_json_path, TRAIN_TEST_SPLIT)

# """Flattening the Data For MLP"""

# X_train_flatten = X_train.reshape((X_train.shape[0], -1))
# X_test_flatten = X_test.reshape((X_test.shape[0], -1))

# """# Initializing Model"""

# network = []
# train_log = [0]
# val_log = []

# # X_train_flatten.shape[1] is input layer
# network.append(Dense(X_train_flatten.shape[1], 1024, learning_rate = LEARNING_RATE)) # Hidden layer with 1024 nuerons
# network.append(ReLU()) # aaply RELU to hidden layer output
# network.append(Dense(1024, NUM_CLASSES, learning_rate = LEARNING_RATE)) # Output layer

# model = MLP(n=network)

# """# Training Model"""

# # Minibatch Stochastic Gradient Descent
# def iterate_minibatches(inputs, targets, batchsize, shuffle=False):
#     assert len(inputs) == len(targets)
#     if shuffle:
#         indices = np.random.permutation(len(inputs))
#     for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):
#         if shuffle:
#             excerpt = indices[start_idx:start_idx + batchsize]
#         else:
#             excerpt = slice(start_idx, start_idx + batchsize)
#         yield inputs[excerpt], targets[excerpt]

# # Training the model
# for epoch in tqdm(range(EPOCHS), desc = "Training"):
#     for x_batch,y_batch in iterate_minibatches(X_train_flatten, y_train, batchsize=BATCH_SIZE, shuffle=SHUFFLE_DATA):
#         model.train(x_batch, y_batch)
    
#     train_log.append(np.mean(model.predict(X_train_flatten)==y_train))

#     print("Epoch", epoch)
#     print("Train accuracy:", train_log[-1])

# plt.plot(train_log, label='train accuracy')
# plt.legend(loc='best')
# plt.grid()
# plt.show()

# # testing and printing predictions on all of the test data
# preds = []
# print("Predicting on all song segments from test data and saving them too...")

# # predicting X test values one by one and sotring
# for i in range(len(X_test_flatten)):
#   y_pred = model.predict(X_test_flatten[i].reshape((1, -1)))
#   preds.append(y_pred[0])

# # Confusion matrix
# cm = confusion_matrix(y_test, preds)

# class_label = z # mapping in json had a list of all classes
# df_cm = pd.DataFrame(cm, index = class_label, columns = class_label)
# sns.heatmap(df_cm, annot = True, fmt= "d", cbar = False)
# plt.title("Confusion Matrix")
# plt.xlabel("Predicted Label")
# plt.ylabel("Actual Label")
# plt.show()

# # Calculating accuracy of model on test set
# accuracy = np.mean(y_test==preds)
# print("\nTest Accuracy:", accuracy)

# """#Validating Data on Outside data"""

def new_voice_predict(audio_path, model, z):
    name = audio_path.split("/")[-1].split("_")[0]
    signal, sample_rate = librosa.load(audio_path, sr=SAMPLE_RATE)
    duration = librosa.get_duration(y=signal, sr=sample_rate) # duration in seconds
    results = []

    d = 0
    for i in range(0, math.floor(duration), TRACK_SAMPLE): # generating mfccs for 10s segments of audio

        if (i+10) > duration:
          continue
    
        start = i * SAMPLE_RATE
        finish = (i + TRACK_SAMPLE) * SAMPLE_RATE

        # OR you can just do
        # data = librosa.load(file_path, sr=SAMPLE_RATE, offset = i, duration = i + TRACK_SAMPLE)

        mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)
        mfcc = mfcc.T
        data = np.array(mfcc.tolist()) # converting to lst
        data = data.reshape((1, -1)) # flattening
        
        prediction = model.predict(data)
        results.append(prediction[0])

    return z[mode(results)], name

# # Testing model on new data
# expected, actual = new_voice_predict("/content/drive/MyDrive/AI_voice_data/TestingData/Fizza Rubab_Test.wav", model, z)
# print("Voice Audio Results => Expected:{}, Actual:{}. Correct Prediction:{}".format(expected, actual, bool(expected==actual)))

# # save the model to disk
# filename = 'VoiceRecognitionModel.pkl'
# pickle.dump(model, open(filename, 'wb'))

# # testing by loading the model
# loaded_model = pickle.load(open('VoiceRecognitionModel.pkl', 'rb'))
# expected, actual = new_voice_predict("/content/drive/MyDrive/AI_voice_data/TestingData/Fizza Rubab_Test.wav", model, z)
# print("Voice Audio Results => Expected:{}, Actual:{}. Correct Prediction:{}".format(expected, actual, bool(expected==actual)))